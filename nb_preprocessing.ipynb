{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "import neurospyke as ns\n",
    "import h5py\n",
    "from scipy.signal import savgol_filter, butter, lfilter, resample\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import os\n",
    "import preprocessing\n",
    "import json\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./settings.json')\n",
    "settings = json.load(f)\n",
    "f.close()\n",
    "\n",
    "sampling_frequency = settings['sampling_frequency']\n",
    "sampling_time = 1 / sampling_frequency\n",
    "resampling_frequency = settings['resampling_frequency']\n",
    "resampling_time = 1 / resampling_frequency\n",
    "\n",
    "frequency_ratio = sampling_frequency / resampling_frequency\n",
    "\n",
    "signal_duration = settings['signal_duration']\n",
    "\n",
    "group = settings['group']\n",
    "subject = settings['subject']\n",
    "conditions = settings['conditions']\n",
    "areas = list(settings['areas'].keys())\n",
    "areas_labels = [settings['areas'][area]['label'] for area in areas]\n",
    "n_channels = settings['n_channels']\n",
    "n_stimuli = settings['n_stimuli']\n",
    "\n",
    "bin_duration = settings['IFR_bin_duration']\n",
    "trial_duration = settings['trial_duration']\n",
    "trial_duration_view = settings['trial_duration_view']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters Setting\n",
    "conditions_idx = 0\n",
    "areas_idx = 0\n",
    "channel = 0\n",
    "channel_labels = ['000', '001', '002', '003', '004', '005', '006', '007', '008', '009', '010', '011', '012', '013', '014', '015']\n",
    "check_transient_idx = 14\n",
    "subject_information = utils.get_subject_information(group, subject, conditions[conditions_idx], areas_labels[areas_idx], channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stimulus Detection\n",
    "raw_data_paths = utils.get_raw_data_paths(group, subject, conditions[conditions_idx], areas)\n",
    "\n",
    "stimulus_idxs_matrix = preprocessing.get_stimulus_idxs_matrix(raw_data_paths, conditions[conditions_idx], settings)\n",
    "stimulus_idxs = preprocessing.get_median_stimulus_idxs(stimulus_idxs_matrix, tolerance_duration=0.1, settings=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis on a single channel, given the stimulus_idxs computed above\n",
    "f = h5py.File(os.path.join('./data', group, subject, conditions[conditions_idx], 'Raw_' + areas[areas_idx] +'_Ch_' + channel_labels[channel] + '.mat'))\n",
    "\n",
    "raw_data = f['data']\n",
    "raw_data = np.reshape(raw_data, np.size(raw_data))\n",
    "raw_data = raw_data[np.arange(signal_duration * sampling_frequency)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stimulus Artifacts Suppression\n",
    "data = np.copy(raw_data)\n",
    "\n",
    "fig_data = ns.visualization.pyplot.figure(figsize=[6, 2])\n",
    "gs = ns.visualization.pyplot.GridSpec(1, 2)\n",
    "ax0 = fig_data.add_subplot(gs[0, 0])\n",
    "ax1 = fig_data.add_subplot(gs[0, 1])\n",
    "fig_data.suptitle(subject_information)\n",
    "\n",
    "ns.visualization.plot_spikes(data, stimulus_idxs, ax=ax0, sampling_time=sampling_time, title='Raw Data')\n",
    "\n",
    "stimulus_duration = 0.002 # seconds\n",
    "stimulus_samples = int(np.round(stimulus_duration * sampling_frequency))\n",
    "stimulus_half_samples = int(np.ceil(stimulus_samples / 2))\n",
    "stimulus_range = np.arange(-stimulus_half_samples, stimulus_half_samples)\n",
    "\n",
    "transient_duration = 0.75 # seconds\n",
    "transient_samples = int(np.ceil(transient_duration * sampling_frequency))\n",
    "transient_range = np.arange(stimulus_half_samples, stimulus_half_samples + transient_samples)\n",
    "\n",
    "for idx in np.arange(np.size(stimulus_idxs)):\n",
    "    stimulus_idx = stimulus_idxs[idx]\n",
    "    data[stimulus_idx + stimulus_range] = 0\n",
    "    transient = data[stimulus_idx + transient_range]\n",
    "\n",
    "    max_idx = np.argmax(transient)\n",
    "    # Ensure a meaningful max_idx, otherwhise set it null\n",
    "    max_idx = max_idx[0] if type(max_idx) == np.ndarray else max_idx\n",
    "    max_idx = 0 if max_idx < 100 else max_idx\n",
    "    max_idx = np.size(transient) if np.abs(np.size(transient) - max_idx) < 100 else max_idx\n",
    "\n",
    "    transient_smoothed = np.zeros(np.shape(transient))\n",
    "\n",
    "    if max_idx != 0:\n",
    "        left_transient_range = np.arange(stimulus_half_samples, stimulus_half_samples + max_idx) - stimulus_half_samples\n",
    "        window_length =  int(np.floor(np.size(left_transient_range) / 5) * 2 + 1) # force odd length\n",
    "        transient_smoothed[left_transient_range] = savgol_filter(transient[left_transient_range], window_length, 3)\n",
    "\n",
    "    if max_idx != np.size(transient):\n",
    "        right_transient_range = transient_range[max_idx:] - stimulus_half_samples\n",
    "        window_length =  int(np.floor(np.size(right_transient_range) / 5) * 2 + 1) # force odd length\n",
    "        transient_smoothed[right_transient_range] = savgol_filter(transient[right_transient_range], window_length, 3)\n",
    "\n",
    "    transient_smoothed = savgol_filter(transient_smoothed, 501, 3) # remove left-right discontinuity\n",
    "\n",
    "    data[stimulus_idx + transient_range] = data[stimulus_idx + transient_range] - transient_smoothed\n",
    "\n",
    "    if idx == check_transient_idx:\n",
    "        fig = ns.visualization.pyplot.figure()\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "        ns.visualization.plot_raw_data(transient, ax=ax, sampling_time=sampling_time)\n",
    "        ns.visualization.plot_raw_data(transient_smoothed, ax=ax, sampling_time=sampling_time, color='#FF0000')\n",
    "        ns.visualization.plot_raw_data(transient - transient_smoothed, ax=ax, sampling_time=sampling_time, color='#00FF00', title='Transient #' + str(idx))\n",
    "\n",
    "        fig.suptitle(subject_information)\n",
    "\n",
    "ns.visualization.plot_spikes(data, stimulus_idxs, ax=ax1, sampling_time=sampling_time, title='Data')\n",
    "fig_data.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num, den = butter(2, [300, 7000], btype='bandpass', fs=sampling_frequency)\n",
    "filtered_data = lfilter(num, den, data)\n",
    "\n",
    "ns.visualization.plot_spikes(filtered_data, stimulus_idxs, sampling_time=sampling_time, title='Filtered Data')\n",
    "ax = ns.visualization.pyplot.gca()\n",
    "ns.visualization.pyplot.text(0.5, 0.98, subject_information, fontsize=8, transform=ax.transAxes, horizontalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import median_abs_deviation\n",
    "threshold = 5*1.4824*median_abs_deviation(filtered_data)\n",
    "spikes_idxs, _ = ns.spikes.hard_threshold_local_maxima(filtered_data, threshold, 0.001, use_abs=True, sampling_time=sampling_time)\n",
    "\n",
    "ns.visualization.plot_spikes(filtered_data, spikes_idxs, sampling_time=sampling_time, title='Spike Detection (HTLM)')\n",
    "ax = ns.visualization.pyplot.gca()\n",
    "ns.visualization.pyplot.text(0.5, 0.98, subject_information, fontsize=8, transform=ax.transAxes, horizontalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns.visualization.plot_spike_train([spikes_idxs, stimulus_idxs], channel_labels=['Spikes', 'Stimuli'], color=['#000000', '#FF0000'], linewidth=0.15, sampling_time=sampling_time, figsize=(9, 1), dpi=100, ylabel='')\n",
    "spike_train = ns.utils.convert_spikes_idxs_to_spike_train(spikes_idxs, sampling_time, duration=signal_duration)\n",
    "ax = ns.visualization.pyplot.gca()\n",
    "ns.visualization.pyplot.text(0.5, 0.97, subject_information, fontsize=8, transform=ax.transAxes, horizontalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IFR Computation\n",
    "IFR, bin_samples = preprocessing.get_IFR(spike_train, bin_duration, sampling_time)\n",
    "ns.visualization.plot_spikes(IFR, stimulus_idxs, sampling_time=sampling_time, title='IFR', ylabel='Spikes/s')\n",
    "ax = ns.visualization.pyplot.gca()\n",
    "ns.visualization.pyplot.text(0.5, 0.98, subject_information, fontsize=8, transform=ax.transAxes, horizontalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IFR Filtering (Gaussian) and Resampling\n",
    "filtered_IFR = gaussian_filter1d(IFR, 0.95 * bin_samples)\n",
    "\n",
    "resampled_IFR = resample(filtered_IFR, int(np.floor(np.size(spike_train, axis=0) / frequency_ratio)))\n",
    "resampled_stimulus_idxs = np.round(stimulus_idxs / frequency_ratio).astype(np.int_)\n",
    "ns.visualization.plot_spikes(resampled_IFR, resampled_stimulus_idxs, sampling_time=resampling_time, title='IFR (filtered and resampled)', ylabel='Spikes/s')\n",
    "ax = ns.visualization.pyplot.gca()\n",
    "ns.visualization.pyplot.text(0.5, 0.98, subject_information, fontsize=8, transform=ax.transAxes, horizontalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IFR Trials Partition\n",
    "IFR_trials = preprocessing.shape_trials(resampled_IFR, resampled_stimulus_idxs, trial_duration=trial_duration_view, sampling_time=resampling_time)\n",
    "\n",
    "n_cols = 6\n",
    "n_rows = int(np.ceil(n_stimuli / n_cols))\n",
    "fig, axs = ns.visualization.pyplot.subplots(n_rows, n_cols, figsize=[12, 8], constrained_layout=True)\n",
    "\n",
    "for trial_idx in np.arange(np.size(IFR_trials, 0)):\n",
    "    row = int(np.floor(trial_idx / n_cols))\n",
    "    col = trial_idx % n_cols\n",
    "\n",
    "    IFR_trial = IFR_trials[trial_idx, :]\n",
    "    \n",
    "    ns.visualization.plot_raw_data(IFR_trial, ax=axs[row, col], sampling_time=resampling_time, title='#' + str(trial_idx + 1), ylabel='spikes/s')\n",
    "\n",
    "fig.suptitle('IFR (all trials)\\n' + subject_information, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spike Train Trials Partition\n",
    "spike_train_trials = preprocessing.shape_trials(spike_train, stimulus_idxs, trial_duration=trial_duration_view, sampling_time=sampling_time)\n",
    "ns.visualization.plot_raster(spike_train_trials, sampling_time, is_train=True, figsize=[3, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('neural')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fc1d4d9a4b8d1ca78615a41ddfacbb8f600609ddb4060fda222c774c81c18ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
